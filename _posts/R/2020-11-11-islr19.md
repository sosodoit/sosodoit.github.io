---
layout: page
title: "[ISLR] 데이터마이닝 솔루션 (19)"
description:
headline: 
categories: data-science
tags: [data-science]
comments: true
published: true
---

## 6.10 변형
일반적으로 모형에 편입된 변수의 수가 늘어나면 훈련 오류(training error)는 감소하나, 테스트 오류(test error)는 그렇지 않다. Simulation dataset을 생성하여 이 현상을 살펴 보자.  

```r
expit = function(t) return(exp(t) / (1 + exp(t)))
n = 1000

set.seed(1110)
X <- matrix(rnorm(1000*20),1000,20)

beta.true = c(0,-10,0,0,20,-30,0,10,20,0,20,10,-10,0,0,0,10,0,-10,0,0)

Xmat = cbind(1,X)
x_theta = Xmat %*% beta.true
y = rbinom(n=n, size=1, prob=expit(x_theta))

df = data.frame(y,X)

n = nrow(df)
n.train = floor(n*0.1); n.test = floor(n*0.9)

set.seed(1)
ind = sample.int(n)
ind.train = ind[1:n.train]
ind.test = ind[(n.train+1):(n.train+n.test)]

df.tr = as.matrix(df[ind.train,])
df.te = as.matrix(df[ind.test,])
x.tr = df.tr[,2:21]
y.tr = df.tr[,1]
x.te = df.te[,2:21]
y.te = df.te[,1]
```

훈련세트를 대상으로 (라쏘 이진 로지스틱 회귀분석)을 λ=2^50,2^49,…,2^(−48),2^(−49)에 대하여 적합
```r
grid = 2^seq(from=50, to=-49, by = -1)

lasso.fit = glmnet(x.tr, y.tr, family="binomial", alpha=1, lambda=grid)
dim(coef(lasso.fit)) # 21 100
## [1]  21 100
#lasso.fit

df <- numeric(length(grid))
for(i in 1:length(grid)){
  
  cof<-coef(lasso.fit)[,i]
  df[i]<-sum(cof!=0)
}

plot(log10(grid),df)
```
<img src="/images/2020-09/islr19-1.png">

```r
error <- numeric(length(grid))
for(i in 1:length(grid)){
  yhat.lasso <- cbind(1,x.tr) %*% coef(lasso.fit)[,i]
  yhat <- ifelse(yhat.lasso > 0.5, 1 ,0)
  
  tbl<-table(yhat,y.tr)
  error[i]<-ifelse(tbl[1,1]+tbl[1,2]==100, tbl[1,2]/nrow(x.tr), (tbl[1,2]+tbl[2,1])/nrow(x.tr))
}
# tbl[1,1]+tbl[1,2]==100 이면 1by2

plot(log10(grid),error)
```
<img src="/images/2020-09/islr19-2.png">

```r
test.error<-numeric(length(grid))
for(i in 1:length(grid)){
  yhat.lasso<-cbind(1,as.matrix(x.te))%*%coef(lasso.fit)[,i]
  yhat<-ifelse(yhat.lasso>0.5,1,0)
  tbl<-table(yhat,y.te)
  test.error[i]<-ifelse(tbl[1,1]+tbl[1,2]==900,tbl[1,2]/nrow(x.te),(tbl[1,2]+tbl[2,1])/nrow(x.te))}

plot(log10(grid),test.error)
```
<img src="/images/2020-09/islr19-3.png">

```r
set.seed(1)
#test error
lambda <- grid[which.min(test.error)] #test error가 최소화 되는 lambda
cof.opt <- coef(lasso.fit)[,which.min(test.error)]

cat("test error가 최소화 되는 lambda =", lambda, "\n그때 test error =", min(test.error), "\n자유도 =", sum(cof.opt!=0))
## test error가 최소화 되는 lambda = 0.001953125 
## 그때 test error = 0.06222222 
## 자유도 = 21
#test error <-> train error 비교
df1 <- lasso.fit$df + 1
dff <- data.frame(lambda = lasso.fit$lambda, df = df1, trainerror = error, testerror = test.error)
head(dff); tail(dff)
##         lambda df trainerror testerror
## 1 1.125900e+15  1        0.5 0.4977778
## 2 5.629500e+14  1        0.5 0.4977778
## 3 2.814750e+14  1        0.5 0.4977778
## 4 1.407375e+14  1        0.5 0.4977778
## 5 7.036874e+13  1        0.5 0.4977778
## 6 3.518437e+13  1        0.5 0.4977778
##           lambda df trainerror  testerror
## 95  5.684342e-14 21          0 0.07888889
## 96  2.842171e-14 21          0 0.07888889
## 97  1.421085e-14 21          0 0.07888889
## 98  7.105427e-15 21          0 0.07888889
## 99  3.552714e-15 21          0 0.07888889
## 100 1.776357e-15 21          0 0.07888889
par(mfrow=c(1,2))
plot(df1, error, type="b", col="red", main="train error")
plot(df1, test.error, type="b", col="blue", main="test error")
```
<img src="/images/2020-09/islr19-4.png">

* test error가 최소화 되는 lambda는 0.001953125이고, 이때 beta hat의 자유도는 21이다. test error와 train error 비교를 위해 전체를 보이기엔 너무 많아, 위아래 6개를 대표적으로 출력하였다. 이 시뮬레이션에서는 train error에서 보면, df가 1일 때보다 df가 21일 때 줄어드는 것을 볼 수 있다. test error에서 보면, df가 1일 때보다 df가 21일 때 줄어드는 것을 볼 수 있다. 그러나 test error가 자유도가 클때 train보다 더 변동성이 있는 것을 볼 수 있다.

```r
result<-numeric(length(grid))

for(i in 1:length(grid)){
cof<-coef(lasso.fit)[,i]
result[i]<-sqrt(sum((cof[-1]-beta.true[-1])^2))
}

plot(log10(grid),result, type="b", col="red", main="lambda vs. beta.hat l_2 추정오차")
```
<img src="/images/2020-09/islr19-5.png">

```r
print(grid[which.min(result)])
## [1] 3.814697e-06
cof.opt<-coef(lasso.fit)[,which.min(result)]
sum(cof.opt!=0) #자유도
## [1] 21
test.error[which.min(error)] # test error가 가장 작은 람다에서의 train error을 찾아봄.
## [1] 0.07888889
```
* 앞서 찾은 자유도가 같다. 이 모형에서는 test error를 최소화시키는 lambda와 beta 추정을 가장 잘하는 lambda가 다르게 나온 것을 볼 수 있다. 일반적으로는 prediction을 잘하는 모형과 추정계수를 잘 예측하는 모형은 다른 것으로 판단된다. 추정계수를 잘 예측한다는 것은 train set에만 잘 맞게 모형을 만드는 것이고 prediction을 잘하기 위해서는 train data 외의 새로운 error를 받아들여야 하므로 두 모형에는 차이가 있을 수밖에 없다고 생각되기 때문이다.