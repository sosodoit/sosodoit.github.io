---
layout: page
title: "[ISLR] 데이터마이닝 솔루션 (9)"
description: ch4
headline:
categories: data-science
tags: [data-science]
comments: true
published: true
---

## 11-(a)
```r
data(Auto)
mpg01 <- ifelse(Auto$mpg > median(Auto$mpg), 1, 0)
auto <- data.frame(Auto, mpg01)
summary(auto)
##       mpg          cylinders      displacement     horsepower        weight    
##  Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  
##  1st Qu.:17.00   1st Qu.:4.000   1st Qu.:105.0   1st Qu.: 75.0   1st Qu.:2225  
##  Median :22.75   Median :4.000   Median :151.0   Median : 93.5   Median :2804  
##  Mean   :23.45   Mean   :5.472   Mean   :194.4   Mean   :104.5   Mean   :2978  
##  3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:275.8   3rd Qu.:126.0   3rd Qu.:3615  
##  Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  
##                                                                                
##   acceleration        year           origin                      name    
##  Min.   : 8.00   Min.   :70.00   Min.   :1.000   amc matador       :  5  
##  1st Qu.:13.78   1st Qu.:73.00   1st Qu.:1.000   ford pinto        :  5  
##  Median :15.50   Median :76.00   Median :1.000   toyota corolla    :  5  
##  Mean   :15.54   Mean   :75.98   Mean   :1.577   amc gremlin       :  4  
##  3rd Qu.:17.02   3rd Qu.:79.00   3rd Qu.:2.000   amc hornet        :  4  
##  Max.   :24.80   Max.   :82.00   Max.   :3.000   chevrolet chevette:  4  
##                                                  (Other)           :365  
##      mpg01    
##  Min.   :0.0  
##  1st Qu.:0.0  
##  Median :0.5  
##  Mean   :0.5  
##  3rd Qu.:1.0  
##  Max.   :1.0  
## 
str(auto)
## 'data.frame':    392 obs. of  10 variables:
##  $ mpg         : num  18 15 18 16 17 15 14 14 14 15 ...
##  $ cylinders   : num  8 8 8 8 8 8 8 8 8 8 ...
##  $ displacement: num  307 350 318 304 302 429 454 440 455 390 ...
##  $ horsepower  : num  130 165 150 150 140 198 220 215 225 190 ...
##  $ weight      : num  3504 3693 3436 3433 3449 ...
##  $ acceleration: num  12 11.5 11 12 10.5 10 9 8.5 10 8.5 ...
##  $ year        : num  70 70 70 70 70 70 70 70 70 70 ...
##  $ origin      : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ name        : Factor w/ 304 levels "amc ambassador brougham",..: 49 36 231 14 161 141 54 223 241 2 ...
##  $ mpg01       : num  0 0 0 0 0 0 0 0 0 0 ...
```

## 11-(b)
```r
#help("pairs") pairs문서에 오픈되어 있는 함수 이용 (산점도와 상관계수를 같이 보기위해)
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

###Q) investigate the association between mpg01 and the other features
#sol)
pairs(auto, lower.panel = panel.smooth, upper.panel = panel.cor)
```
<img src="/images/2020-09/411b.png"  width="700" height="370">

```r
#mpg01과 다른 feature들 간의 산점도와 상관계수를 본 결과, mpg01변수와 cylinders, displacement, horsepower, weight 변수들의 상관계수가 높다는 것을 파악할 수 있었다. 따라서 위 변수들이 mpg01 변수를 예측하는데 도움을 주는 predictors 들이 될 것이라 생각한다.

#mpg01과의 boxplot으로 좀 더 살펴보면,
par(mfrow = c(2,3))
boxplot(cylinders ~ mpg01, data = auto)
boxplot(displacement ~ mpg01, data = auto)
boxplot(horsepower ~ mpg01, data = auto)
boxplot(weight ~ mpg01, data = auto)
boxplot(acceleration ~ mpg01, data = auto)
boxplot(year ~ mpg01, data = auto)
```
<img src="/images/2020-09/4112.png"  width="700" height="370">

- 그림을 보면, 전반적으로 mpg01에 따라 차이가 있어 보이며 cylinders, displacement, horseposer, weight는 상대적으로 acceleration, year에 비해서 mpg01에 따라 차이가 큰 것 것으로 보인다. 따라서 mpg01변수와 cylinders, displacement, horsepower, weight 변수들 사이에 연관성이 있어 보이므로 위 변수들이 mpg01 변수를 예측하는데 유용할 것으로 판단된다.


## 11-(c)
```r
set.seed(1004)
id <- sample(1:nrow(auto), nrow(auto)*0.7) #train_data 0.7, test_data 0.3
train_data <- auto[id,] #training data
test_data <- auto[-id,] #test data
mpg01_train <- auto$mpg01[id] # y train
mpg01_test <- auto$mpg01[-id] # y test

print(paste0('train_data: ', nrow(train_data)))
## [1] "train_data: 274"
print(paste0('test_data: ', nrow(test_data)))
## [1] "test_data: 118"
print(paste0('mpg01_train: ', length(mpg01_train)))
## [1] "mpg01_train: 274"
print(paste0('mpg01_test: ', length(mpg01_test)))
## [1] "mpg01_test: 118"
###Q) Split the data into a training set and a test set
#sol) 
#무작위로 선택한 데이터의 70%를 training data로 분할하고 나머지 30%를 test data로 분할하였다.
```

## 11-(f)
```r
fit_glm <- glm(mpg01 ~ cylinders + weight + displacement + horsepower, data = train_data, family = 'binomial')
summary(fit_glm)
## 
## Call:
## glm(formula = mpg01 ~ cylinders + weight + displacement + horsepower, 
##     family = "binomial", data = train_data)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.2083  -0.2614  -0.0075   0.3506   3.4736  
## 
## Coefficients:
##                Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  11.1655212  1.9551398   5.711 1.12e-08 ***
## cylinders     0.1461731  0.4142328   0.353   0.7242    
## weight       -0.0017855  0.0007951  -2.246   0.0247 *  
## displacement -0.0180245  0.0096407  -1.870   0.0615 .  
## horsepower   -0.0407485  0.0162222  -2.512   0.0120 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 378.08  on 273  degrees of freedom
## Residual deviance: 144.38  on 269  degrees of freedom
## AIC: 154.38
## 
## Number of Fisher Scoring iterations: 7
###Q) logistic regression on the training data, What is the test error of the model obtained?
#sol) 
#(b)에서 가장 관련있어 보인 cylinders, displacement, horsepower, weight 변수들을 가지고 logistic regression을 fit한 결과, 유의수준 0.05 하에서 p_value가 0.05보다 작은 변수는 weight과 horsepower이며, 이 두 변수가 통계적으로 유의한 결과를 가진다.

#train data로 만든 모델로 test data를 가지고 예측해 보면
fit.pred.prob <- predict(fit_glm, test_data, type = "response")
result <- table(round(fit.pred.prob), test_data$mpg01)  #round(fit.pred.prob) <==> ifelse(fit.pred.prob > 0.5, 1, 0)
result
##    
##      0  1
##   0 42  7
##   1  6 63
# round(fit.pred.prob) ==> mpg01은 0과 1, 위 예측값은 확률이므로 잘 예측되었는지 비교하기 위해 반올림으로 0과 1로 만들어주었다.
#0을 0으로 예측한것이 42개, 1을 1로 예측한것이 63개로 나왔다.

error_rate <- (result[1,2]+result[2,1])/nrow(test_data) 
error_rate*100
## [1] 11.01695
#오분류율 = (6 + 7) / 118 = 0.1101695
#로지스틱 모델에서의 오분류율은 11.01695%이다.
```

## 11-(g)
```r
train_x <- train_data[,2:5]
train_y <- mpg01_train
test_x <- test_data[,2:5]
test_y <- mpg01_test

fit_knn <- knn(train_x, test_x, cl=train_y, k = 1)
result <- table(fit_knn,test_y)
result
##        test_y
## fit_knn  0  1
##       0 39 10
##       1  9 60
error_rate <- (result[1,2]+result[2,1])/nrow(test_x)
error_rate*100 
## [1] 16.10169
#오분류율 = (10 + 9) / 118 = 0.1610169

#best k를 찾기 위해 반복문을 만들어 수행시켜 보았다.
store_error <- numeric(nrow(test_x))
for (i in 1:nrow(test_x)) {
  fit_knn <- knn(train_x, test_x, train_y, k = i)
  result <- table(fit_knn,test_y)

  error_rate <- (result[1,2]+result[2,1])/nrow(test_x)
  store_error[i] <- error_rate
}

plot(store_error, type = "l")
idx <- which(store_error == min(store_error))
points(x = idx, store_error[idx], pch = 15, col = "red")
```
<img src="/images/2020-09/411g.png"  width="700" height="370">

```r
idx #이 때가 오분류율이 최저인 군집수가 된다.
##  [1] 55 56 57 59 62 66 75 76 77 80

###Q) KNN on the training data, with several values of K, What test errors do you obtain? Which value of K seems to perform the best on this data set?
#sol) 
#(b)에서 가장 관련있어 보인 cylinders, displacement, horsepower, weight 변수들을 가지고 knn 결과,
#k=1, test error = 16.1%

store_error[idx]*100 #min(store_error)
##  [1] 8.474576 8.474576 8.474576 8.474576 8.474576 8.474576 8.474576 8.474576
##  [9] 8.474576 8.474576

#k=idx인 경우에서 8.5% 정도의 최소의 오분류율을 가짐을 알 수 있다.
#k가 idx인 경우에서 knn을 잘 수행한다고 판단된다.
```